"""
GPU Resource Manager - æ™ºèƒ½æ˜¾å­˜ç®¡ç†ç³»ç»Ÿ

åŠŸèƒ½ï¼š
1. æ‡’åŠ è½½ï¼šé¦–æ¬¡è¯·æ±‚æ—¶åŠ è½½æ¨¡å‹åˆ° GPU
2. å³ç”¨å³å¸ï¼šä»»åŠ¡å®Œæˆåç«‹å³è½¬ç§»åˆ° CPU
3. è‡ªåŠ¨ç›‘æ§ï¼šç©ºé—²è¶…æ—¶åè‡ªåŠ¨é‡Šæ”¾èµ„æº

çŠ¶æ€è½¬æ¢ï¼š
æœªåŠ è½½ â”€â”€é¦–æ¬¡(20-30s)â”€â”€> GPU â”€â”€ä»»åŠ¡å®Œæˆ(2s)â”€â”€> CPU â”€â”€æ–°è¯·æ±‚(2-5s)â”€â”€> GPU
  â†‘                                                    â†“
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€è¶…æ—¶/æ‰‹åŠ¨é‡Šæ”¾(1s)â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
"""

import torch
import threading
import time
import logging
from typing import Callable, Optional, Dict, Any
import gc

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)


class GPUResourceManager:
    """GPU èµ„æºç®¡ç†å™¨ - æ‡’åŠ è½½ + å³ç”¨å³å¸"""

    def __init__(self, idle_timeout: int = 60):
        """
        åˆå§‹åŒ– GPU èµ„æºç®¡ç†å™¨

        Args:
            idle_timeout: ç©ºé—²è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤ 60 ç§’
        """
        self.idle_timeout = idle_timeout
        self.model_on_gpu = None      # GPU ä¸Šçš„æ¨¡å‹
        self.model_on_cpu = None      # CPU ç¼“å­˜çš„æ¨¡å‹
        self.last_use_time = 0        # æœ€åä½¿ç”¨æ—¶é—´
        self.lock = threading.Lock()  # çº¿ç¨‹é”
        self.running = False          # ç›‘æ§çº¿ç¨‹è¿è¡ŒçŠ¶æ€
        self.monitor_thread = None    # ç›‘æ§çº¿ç¨‹
        self.load_func = None         # æ¨¡å‹åŠ è½½å‡½æ•°
        self.model_name = "Model"     # æ¨¡å‹åç§°ï¼ˆç”¨äºæ—¥å¿—ï¼‰

        logger.info(f"ğŸ”§ GPU èµ„æºç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆï¼Œç©ºé—²è¶…æ—¶: {idle_timeout} ç§’")

    def start_monitor(self):
        """å¯åŠ¨ç›‘æ§çº¿ç¨‹"""
        if not self.running:
            self.running = True
            self.monitor_thread = threading.Thread(
                target=self._monitor_loop,
                daemon=True
            )
            self.monitor_thread.start()
            logger.info("ğŸš€ GPU ç›‘æ§çº¿ç¨‹å·²å¯åŠ¨")

    def stop_monitor(self):
        """åœæ­¢ç›‘æ§çº¿ç¨‹"""
        self.running = False
        if self.monitor_thread:
            self.monitor_thread.join(timeout=5)
            logger.info("ğŸ›‘ GPU ç›‘æ§çº¿ç¨‹å·²åœæ­¢")

    def _monitor_loop(self):
        """ç›‘æ§çº¿ç¨‹ä¸»å¾ªç¯"""
        while self.running:
            time.sleep(30)  # æ¯ 30 ç§’æ£€æŸ¥ä¸€æ¬¡

            with self.lock:
                if self.model_on_gpu is not None:
                    idle_time = time.time() - self.last_use_time

                    # è¶…æ—¶è‡ªåŠ¨å¸è½½
                    if idle_time > self.idle_timeout:
                        logger.info(
                            f"â±ï¸  {self.model_name} ç©ºé—² {idle_time:.1f} ç§’ï¼Œ"
                            f"è¶…è¿‡é˜ˆå€¼ {self.idle_timeout} ç§’ï¼Œè‡ªåŠ¨å¸è½½åˆ° CPU"
                        )
                        self._move_to_cpu()

    def get_model(
        self,
        load_func: Callable,
        model_name: str = "Model",
        force_reload: bool = False
    ):
        """
        è·å–æ¨¡å‹ï¼ˆæ‡’åŠ è½½é€»è¾‘ï¼‰

        Args:
            load_func: æ¨¡å‹åŠ è½½å‡½æ•°ï¼Œè¿”å›åŠ è½½å¥½çš„æ¨¡å‹
            model_name: æ¨¡å‹åç§°ï¼ˆç”¨äºæ—¥å¿—æ˜¾ç¤ºï¼‰
            force_reload: æ˜¯å¦å¼ºåˆ¶é‡æ–°åŠ è½½

        Returns:
            åŠ è½½å¥½çš„æ¨¡å‹ï¼ˆåœ¨ GPU ä¸Šï¼‰
        """
        with self.lock:
            self.load_func = load_func
            self.model_name = model_name
            self.last_use_time = time.time()

            # æƒ…å†µ1: æ¨¡å‹å·²åœ¨ GPU ä¸Š
            if self.model_on_gpu is not None and not force_reload:
                logger.info(f"âœ… {model_name} å·²åœ¨ GPU ä¸Šï¼Œç›´æ¥è¿”å›")
                return self.model_on_gpu

            # æƒ…å†µ2: æ¨¡å‹åœ¨ CPU ä¸Šï¼Œå¿«é€Ÿè½¬ç§»åˆ° GPU
            if self.model_on_cpu is not None and not force_reload:
                logger.info(f"ğŸ“¤ {model_name} åœ¨ CPU ä¸Šï¼Œæ­£åœ¨è½¬ç§»åˆ° GPU...")
                start_time = time.time()

                self.model_on_gpu = self._move_to_gpu(self.model_on_cpu)
                self.model_on_cpu = None  # é‡Šæ”¾ CPU ç¼“å­˜

                elapsed = time.time() - start_time
                logger.info(f"âœ… {model_name} å·²è½¬ç§»åˆ° GPUï¼Œè€—æ—¶ {elapsed:.2f} ç§’")

                # æ¸…ç†æ˜¾å­˜
                torch.cuda.empty_cache()
                gc.collect()

                return self.model_on_gpu

            # æƒ…å†µ3: é¦–æ¬¡åŠ è½½ï¼Œä»ç£ç›˜åŠ è½½åˆ° GPU
            logger.info(f"ğŸ”„ é¦–æ¬¡åŠ è½½ {model_name}ï¼Œè¯·ç¨å€™...")
            start_time = time.time()

            self.model_on_gpu = load_func()

            elapsed = time.time() - start_time
            logger.info(f"âœ… {model_name} åŠ è½½å®Œæˆï¼Œè€—æ—¶ {elapsed:.2f} ç§’")

            # æ˜¾ç¤ºæ˜¾å­˜ä½¿ç”¨æƒ…å†µ
            if torch.cuda.is_available():
                for i in range(torch.cuda.device_count()):
                    mem_allocated = torch.cuda.memory_allocated(i) / 1024**3
                    mem_reserved = torch.cuda.memory_reserved(i) / 1024**3
                    logger.info(
                        f"   GPU {i}: å·²åˆ†é… {mem_allocated:.2f} GB, "
                        f"å·²ä¿ç•™ {mem_reserved:.2f} GB"
                    )

            return self.model_on_gpu

    def force_offload(self):
        """
        ç«‹å³å¸è½½ï¼šä»»åŠ¡å®Œæˆåç«‹å³è°ƒç”¨
        å°†æ¨¡å‹ä» GPU è½¬ç§»åˆ° CPUï¼Œé‡Šæ”¾æ˜¾å­˜ï¼ˆ2-5ç§’ï¼‰
        """
        with self.lock:
            if self.model_on_gpu is not None:
                logger.info(f"ğŸ“¥ æ­£åœ¨å¸è½½ {self.model_name} åˆ° CPU...")
                start_time = time.time()

                self._move_to_cpu()

                elapsed = time.time() - start_time
                logger.info(
                    f"âœ… {self.model_name} å·²å¸è½½åˆ° CPUï¼Œè€—æ—¶ {elapsed:.2f} ç§’"
                )

                # æ˜¾ç¤ºé‡Šæ”¾åçš„æ˜¾å­˜
                if torch.cuda.is_available():
                    for i in range(torch.cuda.device_count()):
                        mem_allocated = torch.cuda.memory_allocated(i) / 1024**3
                        logger.info(f"   GPU {i}: å‰©ä½™å ç”¨ {mem_allocated:.2f} GB")

    def force_release(self):
        """
        å®Œå…¨é‡Šæ”¾ï¼šé•¿æœŸä¸ç”¨æ—¶è°ƒç”¨
        æ¸…ç©º GPU å’Œ CPU ç¼“å­˜ï¼ˆ1ç§’ï¼‰
        """
        with self.lock:
            logger.info(f"ğŸ—‘ï¸  æ­£åœ¨å®Œå…¨é‡Šæ”¾ {self.model_name}...")

            self.model_on_gpu = None
            self.model_on_cpu = None

            # å¼ºåˆ¶åƒåœ¾å›æ”¶
            gc.collect()
            if torch.cuda.is_available():
                torch.cuda.empty_cache()

            logger.info(f"âœ… {self.model_name} å·²å®Œå…¨é‡Šæ”¾")

    def get_status(self) -> Dict[str, Any]:
        """
        è·å–å½“å‰çŠ¶æ€

        Returns:
            çŠ¶æ€å­—å…¸
        """
        with self.lock:
            idle_time = time.time() - self.last_use_time if self.last_use_time > 0 else 0

            # ç¡®å®šæ¨¡å‹ä½ç½®
            if self.model_on_gpu is not None:
                location = "GPU"
            elif self.model_on_cpu is not None:
                location = "CPU"
            else:
                location = "æœªåŠ è½½"

            # è·å– GPU æ˜¾å­˜ä¿¡æ¯
            gpu_memory = {}
            if torch.cuda.is_available():
                for i in range(torch.cuda.device_count()):
                    gpu_memory[f"GPU_{i}"] = {
                        "allocated_gb": round(
                            torch.cuda.memory_allocated(i) / 1024**3, 2
                        ),
                        "reserved_gb": round(
                            torch.cuda.memory_reserved(i) / 1024**3, 2
                        ),
                        "total_gb": round(
                            torch.cuda.get_device_properties(i).total_memory / 1024**3, 2
                        )
                    }

            return {
                "model_name": self.model_name,
                "location": location,
                "idle_time_seconds": round(idle_time, 1),
                "idle_timeout_seconds": self.idle_timeout,
                "monitor_running": self.running,
                "gpu_memory": gpu_memory
            }

    def update_timeout(self, new_timeout: int):
        """æ›´æ–°ç©ºé—²è¶…æ—¶æ—¶é—´"""
        with self.lock:
            old_timeout = self.idle_timeout
            self.idle_timeout = new_timeout
            logger.info(
                f"âš™ï¸  ç©ºé—²è¶…æ—¶å·²æ›´æ–°: {old_timeout} ç§’ â†’ {new_timeout} ç§’"
            )

    def _move_to_cpu(self):
        """å†…éƒ¨æ–¹æ³•ï¼šå°†æ¨¡å‹ä» GPU è½¬ç§»åˆ° CPU"""
        if self.model_on_gpu is None:
            return

        # è½¬ç§»åˆ° CPU
        self.model_on_cpu = self.model_on_gpu.cpu()
        self.model_on_gpu = None

        # æ¸…ç†æ˜¾å­˜
        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()

    def _move_to_gpu(self, model):
        """å†…éƒ¨æ–¹æ³•ï¼šå°†æ¨¡å‹ä» CPU è½¬ç§»åˆ° GPU"""
        return model.cuda()


class MultiModelGPUManager:
    """
    å¤šæ¨¡å‹ GPU ç®¡ç†å™¨
    ç”¨äºç®¡ç†å¤šä¸ªæ¨¡å‹ï¼ˆå¦‚ Llasa-8B, XCodec2, WhisperModelï¼‰
    """

    def __init__(self, idle_timeout: int = 60):
        """
        åˆå§‹åŒ–å¤šæ¨¡å‹ç®¡ç†å™¨

        Args:
            idle_timeout: ç©ºé—²è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        """
        self.managers: Dict[str, GPUResourceManager] = {}
        self.idle_timeout = idle_timeout
        self.global_lock = threading.Lock()

        logger.info(f"ğŸ”§ å¤šæ¨¡å‹ GPU ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")

    def register_model(self, model_name: str) -> GPUResourceManager:
        """
        æ³¨å†Œä¸€ä¸ªæ¨¡å‹

        Args:
            model_name: æ¨¡å‹åç§°

        Returns:
            è¯¥æ¨¡å‹çš„ GPU ç®¡ç†å™¨
        """
        with self.global_lock:
            if model_name not in self.managers:
                manager = GPUResourceManager(idle_timeout=self.idle_timeout)
                manager.start_monitor()
                self.managers[model_name] = manager
                logger.info(f"ğŸ“ å·²æ³¨å†Œæ¨¡å‹: {model_name}")

            return self.managers[model_name]

    def get_manager(self, model_name: str) -> Optional[GPUResourceManager]:
        """è·å–æŒ‡å®šæ¨¡å‹çš„ç®¡ç†å™¨"""
        return self.managers.get(model_name)

    def offload_all(self):
        """å¸è½½æ‰€æœ‰æ¨¡å‹åˆ° CPU"""
        logger.info("ğŸ“¥ æ­£åœ¨å¸è½½æ‰€æœ‰æ¨¡å‹åˆ° CPU...")
        for name, manager in self.managers.items():
            manager.force_offload()
        logger.info("âœ… æ‰€æœ‰æ¨¡å‹å·²å¸è½½åˆ° CPU")

    def release_all(self):
        """å®Œå…¨é‡Šæ”¾æ‰€æœ‰æ¨¡å‹"""
        logger.info("ğŸ—‘ï¸  æ­£åœ¨å®Œå…¨é‡Šæ”¾æ‰€æœ‰æ¨¡å‹...")
        for name, manager in self.managers.items():
            manager.force_release()
        logger.info("âœ… æ‰€æœ‰æ¨¡å‹å·²å®Œå…¨é‡Šæ”¾")

    def get_all_status(self) -> Dict[str, Any]:
        """è·å–æ‰€æœ‰æ¨¡å‹çš„çŠ¶æ€"""
        status = {}
        for name, manager in self.managers.items():
            status[name] = manager.get_status()
        return status

    def update_all_timeout(self, new_timeout: int):
        """æ›´æ–°æ‰€æœ‰æ¨¡å‹çš„ç©ºé—²è¶…æ—¶æ—¶é—´"""
        for manager in self.managers.values():
            manager.update_timeout(new_timeout)

    def stop_all(self):
        """åœæ­¢æ‰€æœ‰ç›‘æ§çº¿ç¨‹"""
        logger.info("ğŸ›‘ æ­£åœ¨åœæ­¢æ‰€æœ‰ç›‘æ§çº¿ç¨‹...")
        for manager in self.managers.values():
            manager.stop_monitor()
        logger.info("âœ… æ‰€æœ‰ç›‘æ§çº¿ç¨‹å·²åœæ­¢")


# å…¨å±€å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰
_global_manager: Optional[MultiModelGPUManager] = None


def get_global_manager(idle_timeout: int = 60) -> MultiModelGPUManager:
    """
    è·å–å…¨å±€å¤šæ¨¡å‹ç®¡ç†å™¨ï¼ˆå•ä¾‹ï¼‰

    Args:
        idle_timeout: ç©ºé—²è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰

    Returns:
        å…¨å±€å¤šæ¨¡å‹ç®¡ç†å™¨å®ä¾‹
    """
    global _global_manager
    if _global_manager is None:
        _global_manager = MultiModelGPUManager(idle_timeout=idle_timeout)
    return _global_manager


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    print("=" * 60)
    print("GPU èµ„æºç®¡ç†å™¨æµ‹è¯•")
    print("=" * 60)

    # æ¨¡æ‹Ÿæ¨¡å‹åŠ è½½å‡½æ•°
    def load_dummy_model():
        import time
        print("æ­£åœ¨åŠ è½½æ¨¡å‹...")
        time.sleep(2)  # æ¨¡æ‹ŸåŠ è½½æ—¶é—´

        class DummyModel:
            def __init__(self):
                self.data = torch.randn(1000, 1000).cuda()

            def cpu(self):
                self.data = self.data.cpu()
                return self

            def cuda(self):
                self.data = self.data.cuda()
                return self

        return DummyModel()

    # æµ‹è¯•å•æ¨¡å‹ç®¡ç†å™¨
    print("\næµ‹è¯• 1: å•æ¨¡å‹ç®¡ç†å™¨")
    manager = GPUResourceManager(idle_timeout=10)
    manager.start_monitor()

    # é¦–æ¬¡åŠ è½½
    print("\n1. é¦–æ¬¡åŠ è½½...")
    model = manager.get_model(load_dummy_model, "DummyModel")
    print(f"çŠ¶æ€: {manager.get_status()}")

    # ç«‹å³å¸è½½
    print("\n2. ç«‹å³å¸è½½...")
    manager.force_offload()
    print(f"çŠ¶æ€: {manager.get_status()}")

    # å†æ¬¡è·å–ï¼ˆä» CPU å¿«é€Ÿæ¢å¤ï¼‰
    print("\n3. å†æ¬¡è·å–...")
    model = manager.get_model(load_dummy_model, "DummyModel")
    print(f"çŠ¶æ€: {manager.get_status()}")

    # å®Œå…¨é‡Šæ”¾
    print("\n4. å®Œå…¨é‡Šæ”¾...")
    manager.force_release()
    print(f"çŠ¶æ€: {manager.get_status()}")

    manager.stop_monitor()

    # æµ‹è¯•å¤šæ¨¡å‹ç®¡ç†å™¨
    print("\n\næµ‹è¯• 2: å¤šæ¨¡å‹ç®¡ç†å™¨")
    multi_manager = get_global_manager(idle_timeout=10)

    # æ³¨å†Œå¤šä¸ªæ¨¡å‹
    llasa_manager = multi_manager.register_model("Llasa-8B")
    codec_manager = multi_manager.register_model("XCodec2")

    # åŠ è½½æ¨¡å‹
    print("\n1. åŠ è½½ Llasa-8B...")
    llasa_model = llasa_manager.get_model(load_dummy_model, "Llasa-8B")

    print("\n2. åŠ è½½ XCodec2...")
    codec_model = codec_manager.get_model(load_dummy_model, "XCodec2")

    # æŸ¥çœ‹æ‰€æœ‰çŠ¶æ€
    print("\n3. æ‰€æœ‰æ¨¡å‹çŠ¶æ€:")
    import json
    print(json.dumps(multi_manager.get_all_status(), indent=2, ensure_ascii=False))

    # å¸è½½æ‰€æœ‰
    print("\n4. å¸è½½æ‰€æœ‰æ¨¡å‹...")
    multi_manager.offload_all()

    # å†æ¬¡æŸ¥çœ‹çŠ¶æ€
    print("\n5. å¸è½½åçŠ¶æ€:")
    print(json.dumps(multi_manager.get_all_status(), indent=2, ensure_ascii=False))

    multi_manager.stop_all()

    print("\n" + "=" * 60)
    print("æµ‹è¯•å®Œæˆ!")
    print("=" * 60)
