# Llasa-8B TTS WebUI Docker éƒ¨ç½²æŒ‡å—ï¼ˆæ™ºèƒ½ GPU ç®¡ç†ç‰ˆï¼‰

## âœ¨ æ–°ç‰¹æ€§

æœ¬é¡¹ç›®ç°å·²æ”¯æŒ **GPU æ™ºèƒ½æ˜¾å­˜ç®¡ç†**ï¼š

- âœ… **è‡ªåŠ¨é€‰æ‹©æœ€ç©ºé—²çš„ GPU** - å¯åŠ¨æ—¶è‡ªåŠ¨æ£€æµ‹å¹¶ä½¿ç”¨æ˜¾å­˜å ç”¨æœ€å°‘çš„ GPU
- âœ… **æ‡’åŠ è½½** - é¦–æ¬¡è¯·æ±‚æ—¶æ‰åŠ è½½æ¨¡å‹ï¼ŒåŠ å¿«å¯åŠ¨é€Ÿåº¦
- âœ… **å³ç”¨å³å¸** - ä»»åŠ¡å®Œæˆåç«‹å³é‡Šæ”¾ GPU æ˜¾å­˜ï¼ˆä» 24GB é™è‡³ < 1GBï¼‰
- âœ… **ä¸‰ç§è®¿é—®æ¨¡å¼** - Web UI + REST API + MCPï¼ˆModel Context Protocolï¼‰

è¯¦è§ï¼š[GPU ç®¡ç†æ–‡æ¡£](./GPU_MANAGEMENT.md) | [MCP ä½¿ç”¨æŒ‡å—](./MCP_GUIDE.md)

## ğŸ“‹ ç³»ç»Ÿè¦æ±‚

- **æ“ä½œç³»ç»Ÿ**: Linux (æ¨è Ubuntu 20.04+)
- **GPU**: NVIDIA GPU with CUDA support (è‡³å°‘ 24GB æ˜¾å­˜)
- **è½¯ä»¶ä¾èµ–**:
  - Docker >= 20.10
  - Docker Compose >= 2.0
  - NVIDIA Docker Runtime (nvidia-docker2)
  - NVIDIA Driver >= 525.60.13
  - CUDA >= 12.1

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å…‹éš†æˆ–ä¸‹è½½é¡¹ç›®

```bash
git clone <your-repo-url>
cd Llasa-TTS-8B-WebUI-Demo
```

### 2. èµ‹äºˆè„šæœ¬æ‰§è¡Œæƒé™

```bash
chmod +x start.sh stop.sh
```

### 3. ä¸€é”®å¯åŠ¨

```bash
./start.sh
```

**å¯åŠ¨è„šæœ¬ä¼šè‡ªåŠ¨ï¼š**
- âœ… æ£€æŸ¥ Docker å’Œ NVIDIA Docker ç¯å¢ƒ
- âœ… æ£€æµ‹æ‰€æœ‰ GPU å¹¶æ˜¾ç¤ºçŠ¶æ€
- âœ… **è‡ªåŠ¨é€‰æ‹©æ˜¾å­˜å ç”¨æœ€å°‘çš„ GPU**
- âœ… åˆ›å»º `.env` é…ç½®æ–‡ä»¶
- âœ… åˆ›å»ºå¿…è¦çš„ç›®å½•ï¼ˆmodels_cache, outputs, tempï¼‰
- âœ… æ„å»º Docker é•œåƒ
- âœ… å¯åŠ¨å®¹å™¨

### 4. è®¿é—®æœåŠ¡

å¯åŠ¨æˆåŠŸåï¼Œå¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼è®¿é—®ï¼š

| æœåŠ¡ | åœ°å€ | è¯´æ˜ |
|------|------|------|
| **Web UI** | http://localhost:7860 | Gradio å¯è§†åŒ–ç•Œé¢ |
| **REST API** | http://localhost:7861 | RESTful API æ¥å£ |
| **API æ–‡æ¡£** | http://localhost:7861/apidocs | Swagger API æ–‡æ¡£ |
| **MCP** | é€šè¿‡ MCP å®¢æˆ·ç«¯è¿æ¥ | ç¨‹åºåŒ–è®¿é—®æ¥å£ |

é¦–æ¬¡å¯åŠ¨ä¼šè‡ªåŠ¨ä¸‹è½½æ¨¡å‹ï¼ˆçº¦ 20GBï¼‰ï¼Œè¯·è€å¿ƒç­‰å¾…ã€‚

## ğŸ› ï¸ æ‰‹åŠ¨æ“ä½œ

### æ„å»ºé•œåƒ

```bash
docker-compose build
```

### å¯åŠ¨å®¹å™¨

```bash
docker-compose up -d
```

### æŸ¥çœ‹æ—¥å¿—

```bash
# å®æ—¶æŸ¥çœ‹æ—¥å¿—
docker-compose logs -f

# æŸ¥çœ‹æœ€è¿‘çš„æ—¥å¿—
docker-compose logs --tail=100
```

### åœæ­¢æœåŠ¡

```bash
# ä½¿ç”¨è„šæœ¬
./stop.sh

# æˆ–æ‰‹åŠ¨æ‰§è¡Œ
docker-compose down
```

### é‡å¯æœåŠ¡

```bash
docker-compose restart
```

### è¿›å…¥å®¹å™¨

```bash
docker-compose exec llasa-tts-webui bash
```

## âš™ï¸ é…ç½®è¯´æ˜

### GPU è®¾ç½®

é»˜è®¤é…ç½®ä½¿ç”¨ **GPU 1 å’Œ 2**ï¼ˆå› ä¸ºæ‚¨æåˆ°è¿™ä¸¤ä¸ª GPU æ¯”è¾ƒç©ºé—²ï¼‰ã€‚

å¦‚æœéœ€è¦ä¿®æ”¹ä½¿ç”¨çš„ GPUï¼Œç¼–è¾‘ `docker-compose.yml`:

```yaml
deploy:
  resources:
    reservations:
      devices:
        - driver: nvidia
          device_ids: ['1', '2']  # ä¿®æ”¹è¿™é‡Œï¼Œä¾‹å¦‚æ”¹ä¸º ['0', '1']
          capabilities: [gpu]
```

æˆ–è€…åœ¨å¯åŠ¨æ—¶é€šè¿‡ç¯å¢ƒå˜é‡æŒ‡å®š:

```bash
CUDA_VISIBLE_DEVICES=0,1 docker-compose up -d
```

### HuggingFace Token é…ç½®

å¦‚æœéœ€è¦ä» HuggingFace ä¸‹è½½æ¨¡å‹ï¼Œéœ€è¦è®¾ç½® token:

1. åœ¨ HuggingFace ç½‘ç«™è·å– token: https://huggingface.co/settings/tokens
2. ç¼–è¾‘ `docker-compose.yml`ï¼Œå–æ¶ˆæ³¨é‡Šå¹¶è®¾ç½®:

```yaml
environment:
  - HF_TOKEN=your_huggingface_token_here
```

### ä½¿ç”¨æœ¬åœ°æ¨¡å‹

å¦‚æœå·²ç»ä¸‹è½½äº†æ¨¡å‹åˆ°æœ¬åœ°ï¼Œå¯ä»¥æŒ‚è½½åˆ°å®¹å™¨ï¼š

1. ä¸‹è½½æ¨¡å‹åˆ°æœ¬åœ°ç›®å½•ï¼Œä¾‹å¦‚: `/home/neo/models/Llasa-8B`
2. ä¿®æ”¹ `docker-compose.yml`:

```yaml
volumes:
  - /home/neo/models:/models
```

3. ä¿®æ”¹ `app.py` ä¸­çš„æ¨¡å‹è·¯å¾„:

```python
llasa_8b = '/models/Llasa-8B'
model_path = "/models/xcodec2"
fastwhisper_path = "/models/faster-whisper-large-v3"
```

## ğŸ“Š èµ„æºç›‘æ§

### æŸ¥çœ‹ GPU ä½¿ç”¨æƒ…å†µ

åœ¨å®¹å™¨å†…æ‰§è¡Œ:

```bash
docker-compose exec llasa-tts-webui nvidia-smi
```

åœ¨ä¸»æœºä¸Šæ‰§è¡Œ:

```bash
watch -n 1 nvidia-smi
```

### æŸ¥çœ‹å®¹å™¨èµ„æºä½¿ç”¨

```bash
docker stats llasa-tts-8b-webui
```

## ğŸ› æ•…éšœæ’æŸ¥

### é—®é¢˜ 1: å®¹å™¨å¯åŠ¨å¤±è´¥

**æ£€æŸ¥æ—¥å¿—**:
```bash
docker-compose logs llasa-tts-webui
```

**å¸¸è§åŸå› **:
- GPU ä¸å¯ç”¨æˆ–é©±åŠ¨é—®é¢˜
- æ˜¾å­˜ä¸è¶³
- ç«¯å£ 7860 è¢«å ç”¨

### é—®é¢˜ 2: æ— æ³•è®¿é—® WebUI

**æ£€æŸ¥å®¹å™¨çŠ¶æ€**:
```bash
docker-compose ps
```

**æ£€æŸ¥ç«¯å£**:
```bash
netstat -tulpn | grep 7860
```

### é—®é¢˜ 3: æ¨¡å‹ä¸‹è½½ç¼“æ…¢

**è§£å†³æ–¹æ¡ˆ**:
1. ä½¿ç”¨ HF-Mirror (å·²é»˜è®¤é…ç½®)
2. æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹åˆ°æœ¬åœ°å¹¶æŒ‚è½½
3. ä½¿ç”¨ä»£ç†

### é—®é¢˜ 4: æ˜¾å­˜ä¸è¶³ (OOM)

**è§£å†³æ–¹æ¡ˆ**:
1. ç¡®ä¿ä½¿ç”¨çš„ GPU æœ‰è¶³å¤Ÿæ˜¾å­˜ (è‡³å°‘ 24GB)
2. å…³é—­å…¶ä»–å ç”¨ GPU çš„ç¨‹åº
3. è€ƒè™‘ä½¿ç”¨æ¨¡å‹é‡åŒ– (éœ€è¦ä¿®æ”¹ä»£ç )

### é—®é¢˜ 5: NVIDIA Docker è¿è¡Œæ—¶æœªæ‰¾åˆ°

**å®‰è£… nvidia-docker**:

```bash
# Ubuntu/Debian
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -
curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | \
  sudo tee /etc/apt/sources.list.d/nvidia-docker.list

sudo apt-get update
sudo apt-get install -y nvidia-docker2
sudo systemctl restart docker
```

## ğŸ”§ é«˜çº§é…ç½®

### ä¿®æ”¹ç«¯å£

ç¼–è¾‘ `docker-compose.yml`:

```yaml
ports:
  - "8080:7860"  # å°† 7860 æ”¹ä¸ºä½ æƒ³è¦çš„ç«¯å£
```

### æ·»åŠ èµ„æºé™åˆ¶

ç¼–è¾‘ `docker-compose.yml`ï¼Œå–æ¶ˆæ³¨é‡Š:

```yaml
mem_limit: 32g       # é™åˆ¶å†…å­˜ä½¿ç”¨
shm_size: 8g         # å¢åŠ å…±äº«å†…å­˜
```

### é…ç½®è‡ªåŠ¨é‡å¯

å·²é»˜è®¤é…ç½® `restart: unless-stopped`ï¼Œå®¹å™¨ä¼šåœ¨ç³»ç»Ÿé‡å¯åè‡ªåŠ¨å¯åŠ¨ã€‚

### ä½¿ç”¨å¤–éƒ¨æ•°æ®åº“æˆ–ç¼“å­˜

å¯ä»¥é€šè¿‡ volumes æŒ‚è½½å¤–éƒ¨ç›®å½•æ¥æŒä¹…åŒ–æ•°æ®ã€‚

## ğŸ“š æ¨¡å‹ä¿¡æ¯

### æ‰€éœ€æ¨¡å‹

1. **Llasa-8B** (~17GB æ˜¾å­˜)
   - åœ°å€: https://huggingface.co/HKUSTAudio/Llasa-8B

2. **XCodec2** (~3GB æ˜¾å­˜)
   - åœ°å€: https://huggingface.co/HKUSTAudio/xcodec2

3. **Faster-Whisper-Large-V3** (~3GB æ˜¾å­˜ï¼Œé»˜è®¤ CPU)
   - åœ°å€: https://huggingface.co/Systran/faster-whisper-large-v3

### æ¨¡å‹ç¼“å­˜ä½ç½®

æ‰€æœ‰ä¸‹è½½çš„æ¨¡å‹ä¼šç¼“å­˜åˆ° `./models_cache` ç›®å½•ï¼Œä¸‹æ¬¡å¯åŠ¨æ—¶ä¼šç›´æ¥ä½¿ç”¨ï¼Œæ— éœ€é‡æ–°ä¸‹è½½ã€‚

## ğŸŒ ç½‘ç»œé…ç½®

### å…è®¸å¤–ç½‘è®¿é—®

1. ç¡®ä¿é˜²ç«å¢™å…è®¸ 7860 ç«¯å£
2. WebUI å·²é…ç½®ç›‘å¬ `0.0.0.0`
3. è®¿é—®åœ°å€: `http://your_server_ip:7860`

### å®‰å…¨å»ºè®®

å¦‚æœæš´éœ²åˆ°å…¬ç½‘ï¼Œå»ºè®®ï¼š
- ä½¿ç”¨ Nginx åå‘ä»£ç†
- é…ç½® HTTPS
- æ·»åŠ èº«ä»½è®¤è¯
- ä½¿ç”¨é˜²ç«å¢™é™åˆ¶è®¿é—® IP

## ğŸ“ æ€§èƒ½ä¼˜åŒ–

### 1. ä½¿ç”¨æ›´å¿«çš„é•œåƒæº

å·²åœ¨ Dockerfile ä¸­é…ç½®äº†æ¸…åæºå’Œ HF-Mirrorã€‚

### 2. å¯ç”¨ GPU åŠ é€Ÿ Whisper

ä¿®æ”¹ `app.py`:

```python
fastwhisper_model = WhisperModel(fastwhisper_path, device="cuda")  # æ”¹ä¸º cuda
```

**æ³¨æ„**: è¿™ä¼šé¢å¤–å ç”¨ 3GB æ˜¾å­˜

### 3. æ‰¹é‡å¤„ç†

å¯ä»¥ä¿®æ”¹ä»£ç æ”¯æŒæ‰¹é‡ç”Ÿæˆï¼Œæé«˜ååé‡ã€‚

## ğŸ†˜ è·å–å¸®åŠ©

- **æŸ¥çœ‹æ—¥å¿—**: `docker-compose logs -f`
- **å®˜æ–¹æ¨¡å‹**: https://huggingface.co/HKUSTAudio/Llasa-8B
- **é—®é¢˜åé¦ˆ**: https://github.com/HKUSTAudio/Llasa/issues

## ğŸ“„ License

æœ¬é¡¹ç›®çš„ä»£ç  (app.py) ä½¿ç”¨ MIT Licenseã€‚
æ¨¡å‹å’Œå…¶ä»–ä¾èµ–è¯·å‚è€ƒå…¶å®˜æ–¹ Licenseã€‚
