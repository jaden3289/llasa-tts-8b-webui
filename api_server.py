"""
Llasa-TTS-8B API æœåŠ¡å™¨

æä¾› RESTful API æ¥å£ï¼Œä½¿ç”¨ GPU æ™ºèƒ½ç®¡ç†å™¨
æ”¯æŒ Swagger æ–‡æ¡£
"""

import os
import sys
import time
import logging
from pathlib import Path
from typing import Optional, Dict, Any
import tempfile
import traceback

from flask import Flask, request, jsonify, send_file
from flask_cors import CORS
from flasgger import Swagger, swag_from
import torch
import torchaudio
from transformers import AutoTokenizer, AutoModelForCausalLM
from faster_whisper import WhisperModel
from xcodec2.modeling_xcodec2 import XCodec2Model

# å¯¼å…¥ GPU ç®¡ç†å™¨
from gpu_manager import get_global_manager

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s'
)
logger = logging.getLogger(__name__)

# ============================================================================
# Flask åº”ç”¨åˆå§‹åŒ–
# ============================================================================

app = Flask(__name__)
CORS(app)  # å¯ç”¨ CORS

# Swagger é…ç½®
swagger_config = {
    "headers": [],
    "specs": [
        {
            "endpoint": 'apispec',
            "route": '/apispec.json',
            "rule_filter": lambda rule: True,
            "model_filter": lambda tag: True,
        }
    ],
    "static_url_path": "/flasgger_static",
    "swagger_ui": True,
    "specs_route": "/apidocs"
}

swagger_template = {
    "swagger": "2.0",
    "info": {
        "title": "Llasa-TTS-8B API",
        "description": "è¯­éŸ³å…‹éš† / TTS API with GPU Smart Management",
        "version": "1.0.0"
    },
    "basePath": "/api",
    "schemes": ["http", "https"]
}

swagger = Swagger(app, config=swagger_config, template=swagger_template)

# ============================================================================
# å…¨å±€å˜é‡
# ============================================================================

# GPU ç®¡ç†å™¨
gpu_manager = get_global_manager(
    idle_timeout=int(os.getenv('GPU_IDLE_TIMEOUT', 600))
)

# æ¨¡å‹è·¯å¾„
LLASA_MODEL_PATH = os.getenv('LLASA_MODEL_PATH', 'HKUSTAudio/Llasa-8B')
XCODEC_MODEL_PATH = os.getenv('XCODEC_MODEL_PATH', 'HKUSTAudio/xcodec2')
WHISPER_MODEL_PATH = os.getenv('WHISPER_MODEL_PATH', 'Systran/faster-whisper-large-v3')
WHISPER_DEVICE = os.getenv('WHISPER_DEVICE', 'cpu')

# æ¨¡å‹å®ä¾‹ï¼ˆæ‡’åŠ è½½ï¼‰
whisper_model = None
llasa_tokenizer = None

# è¾“å‡ºç›®å½•
OUTPUT_DIR = Path(os.getenv('OUTPUTS_DIR', './outputs'))
OUTPUT_DIR.mkdir(exist_ok=True, parents=True)

# ============================================================================
# æ¨¡å‹åŠ è½½å‡½æ•°
# ============================================================================

def load_llasa_model():
    """åŠ è½½ Llasa-8B æ¨¡å‹"""
    logger.info(f"æ­£åœ¨åŠ è½½ Llasa-8B æ¨¡å‹: {LLASA_MODEL_PATH}")
    model = AutoModelForCausalLM.from_pretrained(
        LLASA_MODEL_PATH,
        torch_dtype=torch.float16,
        device_map='cuda'
    )
    model.eval()
    return model


def load_xcodec_model():
    """åŠ è½½ XCodec2 æ¨¡å‹"""
    logger.info(f"æ­£åœ¨åŠ è½½ XCodec2 æ¨¡å‹: {XCODEC_MODEL_PATH}")
    model = XCodec2Model.from_pretrained(XCODEC_MODEL_PATH, device_map='cuda')
    model.eval()
    return model


def get_whisper_model():
    """è·å– Whisper æ¨¡å‹ï¼ˆé GPU ç®¡ç†ï¼‰"""
    global whisper_model
    if whisper_model is None:
        logger.info(f"æ­£åœ¨åŠ è½½ Whisper æ¨¡å‹: {WHISPER_MODEL_PATH}")
        whisper_model = WhisperModel(WHISPER_MODEL_PATH, device=WHISPER_DEVICE)
    return whisper_model


def get_tokenizer():
    """è·å– Tokenizerï¼ˆé GPU ç®¡ç†ï¼‰"""
    global llasa_tokenizer
    if llasa_tokenizer is None:
        logger.info(f"æ­£åœ¨åŠ è½½ Tokenizer: {LLASA_MODEL_PATH}")
        llasa_tokenizer = AutoTokenizer.from_pretrained(LLASA_MODEL_PATH)
    return llasa_tokenizer


# ============================================================================
# è¾…åŠ©å‡½æ•°
# ============================================================================

def ids_to_speech_tokens(speech_ids):
    """å°† speech IDs è½¬æ¢ä¸º token å­—ç¬¦ä¸²"""
    return [f"<|s_{sid}|>" for sid in speech_ids]


def extract_speech_ids(speech_tokens_str):
    """ä» token å­—ç¬¦ä¸²æå– speech IDs"""
    speech_ids = []
    for token_str in speech_tokens_str:
        if token_str.startswith('<|s_') and token_str.endswith('|>'):
            num_str = token_str[4:-2]
            speech_ids.append(int(num_str))
    return speech_ids


def tts_process(
    audio_path: str,
    ref_text: str,
    target_text: str,
    system_prompt: str = "Convert the text to speech",
    sample_rate: int = 24000,
    temperature: float = 1.0,
    top_k: int = 50,
    top_p: float = 0.9,
    penalty: float = 1.2,
    do_sample: bool = True,
    random_seed: int = 49
) -> Optional[str]:
    """
    TTS å¤„ç†æµç¨‹ï¼ˆä½¿ç”¨ GPU ç®¡ç†å™¨ï¼‰

    Returns:
        ç”Ÿæˆçš„éŸ³é¢‘æ–‡ä»¶è·¯å¾„
    """
    try:
        # è®¾ç½®éšæœºç§å­
        torch.manual_seed(random_seed)
        torch.cuda.manual_seed_all(random_seed)

        # 1. åŠ è½½éŸ³é¢‘
        waveform, sr = torchaudio.load(audio_path)

        # ç«‹ä½“å£°è½¬å•å£°é“
        if waveform.size(0) > 1:
            waveform = torch.mean(waveform, dim=0, keepdim=True)

        # é‡é‡‡æ ·
        prompt_wav = torchaudio.transforms.Resample(
            orig_freq=sr,
            new_freq=sample_rate
        )(waveform)

        input_text = ref_text + ' ' + target_text

        # 2. è·å–æ¨¡å‹ï¼ˆæ‡’åŠ è½½ï¼‰
        codec_manager = gpu_manager.register_model("XCodec2")
        llasa_manager = gpu_manager.register_model("Llasa-8B")

        try:
            # è·å– XCodec2
            codec_model = codec_manager.get_model(load_xcodec_model, "XCodec2")

            # ç¼–ç éŸ³é¢‘
            with torch.no_grad():
                vq_code_prompt = codec_model.encode_code(input_waveform=prompt_wav)
                vq_code_prompt = vq_code_prompt[0, 0, :]
                speech_ids_prefix = ids_to_speech_tokens(vq_code_prompt)

            # ç«‹å³å¸è½½ Codec
            codec_manager.force_offload()

            # è·å– Llasa-8B
            llasa_model = llasa_manager.get_model(load_llasa_model, "Llasa-8B")
            tokenizer = get_tokenizer()

            # å‡†å¤‡è¾“å…¥
            formatted_text = f"<|TEXT_UNDERSTANDING_START|>{input_text}<|TEXT_UNDERSTANDING_END|>"
            chat = [
                {"role": "user", "content": system_prompt + ":" + formatted_text},
                {"role": "assistant", "content": "<|SPEECH_GENERATION_START|>" + ''.join(speech_ids_prefix)}
            ]

            input_ids = tokenizer.apply_chat_template(
                chat,
                tokenize=True,
                return_tensors='pt',
                continue_final_message=True
            ).cuda()

            speech_end_id = tokenizer.convert_tokens_to_ids('<|SPEECH_GENERATION_END|>')

            # ç”Ÿæˆè¯­éŸ³ token
            with torch.no_grad():
                outputs = llasa_model.generate(
                    input_ids,
                    max_length=2048,
                    eos_token_id=speech_end_id,
                    do_sample=do_sample,
                    top_p=top_p,
                    top_k=top_k,
                    temperature=temperature,
                    repetition_penalty=penalty
                )

            generated_ids = outputs[0][input_ids.shape[1]-len(speech_ids_prefix):-1]
            speech_tokens = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)
            speech_tokens = extract_speech_ids(speech_tokens)
            speech_tokens = torch.tensor(speech_tokens).cuda().unsqueeze(0).unsqueeze(0)

            # ç«‹å³å¸è½½ Llasa
            llasa_manager.force_offload()

            # é‡æ–°è·å– Codec è¿›è¡Œè§£ç 
            codec_model = codec_manager.get_model(load_xcodec_model, "XCodec2")

            # è§£ç éŸ³é¢‘
            with torch.no_grad():
                gen_wav = codec_model.decode_code(speech_tokens)
                gen_wav = gen_wav[:, :, prompt_wav.shape[1]:]

            # ç«‹å³å¸è½½ Codec
            codec_manager.force_offload()

            # ä¿å­˜éŸ³é¢‘
            output_path = OUTPUT_DIR / f"output_{int(time.time())}.wav"
            torchaudio.save(
                str(output_path),
                gen_wav[0].cpu(),
                sample_rate
            )

            logger.info(f"âœ… éŸ³é¢‘ç”ŸæˆæˆåŠŸ: {output_path}")
            return str(output_path)

        except Exception as e:
            # ç¡®ä¿å¼‚å¸¸æ—¶ä¹Ÿå¸è½½æ¨¡å‹
            codec_manager.force_offload()
            llasa_manager.force_offload()
            raise e

    except Exception as e:
        logger.error(f"TTS å¤„ç†å¤±è´¥: {e}")
        logger.error(traceback.format_exc())
        return None


# ============================================================================
# API ç«¯ç‚¹
# ============================================================================

@app.route('/health', methods=['GET'])
def health_check():
    """
    å¥åº·æ£€æŸ¥
    ---
    tags:
      - System
    responses:
      200:
        description: ç³»ç»Ÿæ­£å¸¸
    """
    return jsonify({
        'status': 'healthy',
        'timestamp': time.time()
    })


@app.route('/api/gpu/status', methods=['GET'])
def get_gpu_status():
    """
    è·å– GPU çŠ¶æ€
    ---
    tags:
      - GPU Management
    responses:
      200:
        description: GPU çŠ¶æ€ä¿¡æ¯
    """
    status = gpu_manager.get_all_status()
    return jsonify(status)


@app.route('/api/gpu/offload', methods=['POST'])
def offload_gpu():
    """
    æ‰‹åŠ¨å¸è½½æ‰€æœ‰æ¨¡å‹åˆ° CPU
    ---
    tags:
      - GPU Management
    responses:
      200:
        description: å¸è½½æˆåŠŸ
    """
    gpu_manager.offload_all()
    return jsonify({
        'status': 'success',
        'message': 'æ‰€æœ‰æ¨¡å‹å·²å¸è½½åˆ° CPU'
    })


@app.route('/api/gpu/release', methods=['POST'])
def release_gpu():
    """
    å®Œå…¨é‡Šæ”¾æ‰€æœ‰æ¨¡å‹
    ---
    tags:
      - GPU Management
    responses:
      200:
        description: é‡Šæ”¾æˆåŠŸ
    """
    gpu_manager.release_all()
    return jsonify({
        'status': 'success',
        'message': 'æ‰€æœ‰æ¨¡å‹å·²å®Œå…¨é‡Šæ”¾'
    })


@app.route('/api/transcribe', methods=['POST'])
def transcribe_audio():
    """
    è½¬å½•éŸ³é¢‘ï¼ˆASRï¼‰
    ---
    tags:
      - TTS
    parameters:
      - name: audio
        in: formData
        type: file
        required: true
        description: éŸ³é¢‘æ–‡ä»¶
    responses:
      200:
        description: è½¬å½•ç»“æœ
    """
    if 'audio' not in request.files:
        return jsonify({'error': 'æœªä¸Šä¼ éŸ³é¢‘æ–‡ä»¶'}), 400

    audio_file = request.files['audio']

    # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
    with tempfile.NamedTemporaryFile(delete=False, suffix='.wav') as tmp:
        audio_file.save(tmp.name)
        tmp_path = tmp.name

    try:
        whisper = get_whisper_model()
        segments, info = whisper.transcribe(
            audio=tmp_path,
            beam_size=5,
            vad_filter=True,
            vad_parameters=dict(min_silence_duration_ms=700)
        )

        text = ""
        for segment in segments:
            text += segment.text + "\n"

        return jsonify({
            'text': text.strip(),
            'language': info.language if hasattr(info, 'language') else None
        })

    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        Path(tmp_path).unlink(missing_ok=True)


@app.route('/api/tts', methods=['POST'])
def tts_generate():
    """
    ç”Ÿæˆè¯­éŸ³
    ---
    tags:
      - TTS
    parameters:
      - name: audio
        in: formData
        type: file
        required: true
        description: å‚è€ƒéŸ³é¢‘æ–‡ä»¶
      - name: ref_text
        in: formData
        type: string
        required: true
        description: å‚è€ƒéŸ³é¢‘çš„æ–‡æœ¬
      - name: target_text
        in: formData
        type: string
        required: true
        description: è¦ç”Ÿæˆçš„æ–‡æœ¬
      - name: system_prompt
        in: formData
        type: string
        required: false
        description: ç³»ç»Ÿæç¤ºè¯
      - name: sample_rate
        in: formData
        type: integer
        required: false
        description: é‡‡æ ·ç‡ï¼ˆé»˜è®¤ 24000ï¼‰
      - name: temperature
        in: formData
        type: number
        required: false
        description: Temperatureï¼ˆé»˜è®¤ 1.0ï¼‰
      - name: top_k
        in: formData
        type: integer
        required: false
        description: Top-Kï¼ˆé»˜è®¤ 50ï¼‰
      - name: top_p
        in: formData
        type: number
        required: false
        description: Top-Pï¼ˆé»˜è®¤ 0.9ï¼‰
      - name: penalty
        in: formData
        type: number
        required: false
        description: é‡å¤æƒ©ç½šï¼ˆé»˜è®¤ 1.2ï¼‰
      - name: random_seed
        in: formData
        type: integer
        required: false
        description: éšæœºç§å­ï¼ˆé»˜è®¤ 49ï¼‰
    responses:
      200:
        description: ç”Ÿæˆçš„éŸ³é¢‘æ–‡ä»¶
      400:
        description: å‚æ•°é”™è¯¯
      500:
        description: ç”Ÿæˆå¤±è´¥
    """
    # å‚æ•°éªŒè¯
    if 'audio' not in request.files:
        return jsonify({'error': 'æœªä¸Šä¼ å‚è€ƒéŸ³é¢‘'}), 400

    ref_text = request.form.get('ref_text', '').strip()
    target_text = request.form.get('target_text', '').strip()

    if not ref_text or not target_text:
        return jsonify({'error': 'ç¼ºå°‘å¿…éœ€çš„æ–‡æœ¬å‚æ•°'}), 400

    # è·å–å‚æ•°
    system_prompt = request.form.get('system_prompt', 'Convert the text to speech')
    sample_rate = int(request.form.get('sample_rate', 24000))
    temperature = float(request.form.get('temperature', 1.0))
    top_k = int(request.form.get('top_k', 50))
    top_p = float(request.form.get('top_p', 0.9))
    penalty = float(request.form.get('penalty', 1.2))
    random_seed = int(request.form.get('random_seed', 49))

    # ä¿å­˜éŸ³é¢‘
    audio_file = request.files['audio']
    with tempfile.NamedTemporaryFile(delete=False, suffix='.wav') as tmp:
        audio_file.save(tmp.name)
        tmp_audio_path = tmp.name

    try:
        # å¤„ç† TTS
        output_path = tts_process(
            audio_path=tmp_audio_path,
            ref_text=ref_text,
            target_text=target_text,
            system_prompt=system_prompt,
            sample_rate=sample_rate,
            temperature=temperature,
            top_k=top_k,
            top_p=top_p,
            penalty=penalty,
            random_seed=random_seed
        )

        if output_path and Path(output_path).exists():
            return send_file(
                output_path,
                mimetype='audio/wav',
                as_attachment=True,
                download_name=f'generated_{int(time.time())}.wav'
            )
        else:
            return jsonify({'error': 'éŸ³é¢‘ç”Ÿæˆå¤±è´¥'}), 500

    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        Path(tmp_audio_path).unlink(missing_ok=True)


# ============================================================================
# ä¸»å‡½æ•°
# ============================================================================

if __name__ == '__main__':
    port = int(os.getenv('API_SERVER_PORT', 7861))

    logger.info(f"ğŸš€ å¯åŠ¨ Llasa-TTS-8B API æœåŠ¡å™¨")
    logger.info(f"ğŸ“Š è®¿é—®åœ°å€: http://0.0.0.0:{port}")
    logger.info(f"ğŸ“– API æ–‡æ¡£: http://0.0.0.0:{port}/apidocs")

    app.run(
        host='0.0.0.0',
        port=port,
        debug=False
    )
